{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBirENkpIUf8U1RU6dNcT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeedumiRashmika/Researchbasic/blob/main/Untitled16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AY8OM4om0Wk",
        "outputId": "b021166b-f64b-471e-c2ab-8f24aa7a54a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n"
      ],
      "metadata": {
        "id": "hchCVTArm9ws"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # choose both model1_dataset.xlsx and model2_srilanka_1500_rows.xlsx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ir43sp5LnGSc",
        "outputId": "317b9822-1bc5-4a11-eba0-d7f89ce89fa1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-86ea093b-db57-4e5e-a6f1-9dec5c2ac3e3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-86ea093b-db57-4e5e-a6f1-9dec5c2ac3e3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model1_data.xlsx to model1_data (1).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # choose both model1_dataset.xlsx and model2_srilanka_1500_rows.xlsx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "b5nCkBZxnQmI",
        "outputId": "8ebebb49-e874-48a1-8f90-bede7e3017ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-57d3b791-e6d2-49d5-88c2-104f1ecf0db9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-57d3b791-e6d2-49d5-88c2-104f1ecf0db9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model2_srilanka_1500_rows.xlsx to model2_srilanka_1500_rows.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model 1 dataset\n",
        "df1 = pd.read_excel(\"model1_data.xlsx\")  # change if your file name is different\n",
        "\n",
        "print(\"Model 1 head:\")\n",
        "print(df1.head())\n",
        "print(\"Columns:\", df1.columns.tolist())\n",
        "\n",
        "# Drop fully empty rows\n",
        "df1 = df1.dropna(how=\"all\")\n",
        "\n",
        "# Drop rows missing important values\n",
        "df1 = df1.dropna(subset=[\n",
        "    \"batch_ripeness_level\",\n",
        "    \"batch_avg_weight_g\",\n",
        "    \"temperature_C\",\n",
        "    \"humidity_%\",\n",
        "    \"storage_days_before_shipping\",\n",
        "    \"shelf_life_days\"\n",
        "])\n",
        "\n",
        "print(\"Rows after cleaning (Model 1):\", len(df1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhFxqsFioPXD",
        "outputId": "e44a2b5a-8b85-4576-b288-ec6ba3b4df4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 head:\n",
            "  batch_ripeness_level  batch_avg_weight_g  temperature_C  humidity_%  \\\n",
            "0               Unripe               302.0           10.0        68.0   \n",
            "1            Semi-ripe               288.0           13.0        72.0   \n",
            "2                 Ripe               315.0           18.0        80.0   \n",
            "3               Unripe               270.0           12.0        65.0   \n",
            "4            Semi-ripe               295.0           15.0        75.0   \n",
            "\n",
            "   storage_days_before_shipping  shelf_life_days  \n",
            "0                           1.0               17  \n",
            "1                           1.0               10  \n",
            "2                           0.0                4  \n",
            "3                           2.0               16  \n",
            "4                           1.0                9  \n",
            "Columns: ['batch_ripeness_level', 'batch_avg_weight_g', 'temperature_C', 'humidity_%', 'storage_days_before_shipping', 'shelf_life_days']\n",
            "Rows after cleaning (Model 1): 1050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target\n",
        "X1 = df1[[\n",
        "    \"batch_ripeness_level\",\n",
        "    \"batch_avg_weight_g\",\n",
        "    \"temperature_C\",\n",
        "    \"humidity_%\",\n",
        "    \"storage_days_before_shipping\"\n",
        "]]\n",
        "\n",
        "y1 = df1[\"shelf_life_days\"].values.astype(\"float32\")\n",
        "\n",
        "# Split train/test\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
        "    X1, y1, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Categorical & numeric columns\n",
        "cat_cols_1 = [\"batch_ripeness_level\"]\n",
        "num_cols_1 = [\"batch_avg_weight_g\", \"temperature_C\", \"humidity_%\", \"storage_days_before_shipping\"]\n",
        "\n",
        "# Preprocessor (sklearn) → One-hot + Scale\n",
        "preprocessor_1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_1),\n",
        "        (\"num\", StandardScaler(), num_cols_1)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Fit on train, transform train & test\n",
        "X1_train_proc = preprocessor_1.fit_transform(X1_train)\n",
        "X1_test_proc  = preprocessor_1.transform(X1_test)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X1_train_proc = X1_train_proc.toarray() if hasattr(X1_train_proc, \"toarray\") else X1_train_proc\n",
        "X1_test_proc  = X1_test_proc.toarray() if hasattr(X1_test_proc, \"toarray\") else X1_test_proc\n",
        "\n",
        "print(\"Processed Model 1 shape:\", X1_train_proc.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO2ZSZWFpgtJ",
        "outputId": "a4dd9483-61d3-484e-ee3c-10f123b34eeb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Model 1 shape: (840, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim_1 = X1_train_proc.shape[1]\n",
        "\n",
        "model1_tf = models.Sequential([\n",
        "    layers.Input(shape=(input_dim_1,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(1)  # regression output\n",
        "])\n",
        "\n",
        "model1_tf.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "model1_tf.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Bzv3bRtppnSZ",
        "outputId": "b536a9a7-ad77-4492-9f7b-f175d54f7ff8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,137\u001b[0m (12.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,137\u001b[0m (12.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1_tf.fit(\n",
        "    X1_train_proc, y1_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,         # you can adjust (e.g., 50–100)\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzTpVGG8pukB",
        "outputId": "ef9aa9b7-53ad-4b1d-a3f7-4b1cda435e44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 122.9542 - mae: 9.5040 - val_loss: 108.5544 - val_mae: 8.8976\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 88.3687 - mae: 7.6844 - val_loss: 53.0675 - val_mae: 6.2096\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 33.0249 - mae: 4.7861 - val_loss: 7.0789 - val_mae: 2.0721\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.9680 - mae: 1.8567 - val_loss: 4.7604 - val_mae: 1.6357\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5147 - mae: 1.3950 - val_loss: 4.0074 - val_mae: 1.4484\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0426 - mae: 1.3128 - val_loss: 3.4406 - val_mae: 1.3675\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8056 - mae: 1.2386 - val_loss: 3.1974 - val_mae: 1.2882\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3229 - mae: 1.1061 - val_loss: 2.9102 - val_mae: 1.2338\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2627 - mae: 1.0524 - val_loss: 2.6919 - val_mae: 1.1828\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1194 - mae: 1.0259 - val_loss: 2.5373 - val_mae: 1.1425\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3728 - mae: 1.0634 - val_loss: 2.3362 - val_mae: 1.0976\n",
            "Epoch 12/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6996 - mae: 0.9152 - val_loss: 2.1743 - val_mae: 1.0692\n",
            "Epoch 13/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6626 - mae: 0.9093 - val_loss: 2.0304 - val_mae: 1.0345\n",
            "Epoch 14/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5095 - mae: 0.8506 - val_loss: 1.9036 - val_mae: 0.9932\n",
            "Epoch 15/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5439 - mae: 0.8811 - val_loss: 1.7589 - val_mae: 0.9563\n",
            "Epoch 16/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2999 - mae: 0.7985 - val_loss: 1.6509 - val_mae: 0.9417\n",
            "Epoch 17/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1572 - mae: 0.7546 - val_loss: 1.5120 - val_mae: 0.8875\n",
            "Epoch 18/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2159 - mae: 0.7670 - val_loss: 1.4067 - val_mae: 0.8623\n",
            "Epoch 19/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0056 - mae: 0.7084 - val_loss: 1.3120 - val_mae: 0.8301\n",
            "Epoch 20/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0072 - mae: 0.7062 - val_loss: 1.2306 - val_mae: 0.8099\n",
            "Epoch 21/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9727 - mae: 0.6844 - val_loss: 1.1547 - val_mae: 0.7785\n",
            "Epoch 22/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8200 - mae: 0.6239 - val_loss: 1.0853 - val_mae: 0.7601\n",
            "Epoch 23/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8273 - mae: 0.6618 - val_loss: 1.0312 - val_mae: 0.7397\n",
            "Epoch 24/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7353 - mae: 0.6263 - val_loss: 0.9863 - val_mae: 0.7345\n",
            "Epoch 25/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6993 - mae: 0.6096 - val_loss: 0.9565 - val_mae: 0.7265\n",
            "Epoch 26/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7171 - mae: 0.6158 - val_loss: 0.9141 - val_mae: 0.7030\n",
            "Epoch 27/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7145 - mae: 0.6264 - val_loss: 0.8859 - val_mae: 0.6882\n",
            "Epoch 28/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7712 - mae: 0.6423 - val_loss: 0.8638 - val_mae: 0.6840\n",
            "Epoch 29/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6249 - mae: 0.5746 - val_loss: 0.8529 - val_mae: 0.6843\n",
            "Epoch 30/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5977 - mae: 0.5760 - val_loss: 0.8316 - val_mae: 0.6732\n",
            "Epoch 31/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6325 - mae: 0.5738 - val_loss: 0.8060 - val_mae: 0.6641\n",
            "Epoch 32/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5235 - mae: 0.5266 - val_loss: 0.8024 - val_mae: 0.6661\n",
            "Epoch 33/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5936 - mae: 0.5697 - val_loss: 0.7856 - val_mae: 0.6583\n",
            "Epoch 34/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5442 - mae: 0.5454 - val_loss: 0.8043 - val_mae: 0.6640\n",
            "Epoch 35/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5735 - mae: 0.5678 - val_loss: 0.7789 - val_mae: 0.6531\n",
            "Epoch 36/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6587 - mae: 0.5863 - val_loss: 0.7736 - val_mae: 0.6511\n",
            "Epoch 37/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6163 - mae: 0.5760 - val_loss: 0.8543 - val_mae: 0.6821\n",
            "Epoch 38/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6256 - mae: 0.5683 - val_loss: 0.7598 - val_mae: 0.6430\n",
            "Epoch 39/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5983 - mae: 0.5558 - val_loss: 0.7892 - val_mae: 0.6580\n",
            "Epoch 40/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5670 - mae: 0.5710 - val_loss: 0.7841 - val_mae: 0.6528\n",
            "Epoch 41/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5520 - mae: 0.5647 - val_loss: 0.7612 - val_mae: 0.6438\n",
            "Epoch 42/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5616 - mae: 0.5568 - val_loss: 0.7536 - val_mae: 0.6447\n",
            "Epoch 43/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5063 - mae: 0.5234 - val_loss: 0.8049 - val_mae: 0.6692\n",
            "Epoch 44/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5844 - mae: 0.5768 - val_loss: 0.8143 - val_mae: 0.6797\n",
            "Epoch 45/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5908 - mae: 0.5665 - val_loss: 0.7459 - val_mae: 0.6382\n",
            "Epoch 46/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5788 - mae: 0.5488 - val_loss: 0.7560 - val_mae: 0.6424\n",
            "Epoch 47/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5427 - mae: 0.5349 - val_loss: 0.7875 - val_mae: 0.6506\n",
            "Epoch 48/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5184 - mae: 0.5408 - val_loss: 0.7418 - val_mae: 0.6302\n",
            "Epoch 49/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5720 - mae: 0.5507 - val_loss: 0.7479 - val_mae: 0.6410\n",
            "Epoch 50/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5300 - mae: 0.5459 - val_loss: 0.7404 - val_mae: 0.6363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on test set\n",
        "y1_pred = model1_tf.predict(X1_test_proc).flatten()\n",
        "\n",
        "mae1 = mean_absolute_error(y1_test, y1_pred)\n",
        "r2_1 = r2_score(y1_test, y1_pred)\n",
        "\n",
        "print(\"===== MODEL 1 – Shelf Life (TensorFlow) =====\")\n",
        "print(\"MAE:\", mae1)\n",
        "print(\"R²:\", r2_1)\n",
        "print(\"============================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeeZBxDEp6wV",
        "outputId": "f40fa853-727c-4f5c-f2ab-5be55d4f1fce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "===== MODEL 1 – Shelf Life (TensorFlow) =====\n",
            "MAE: 0.5169797539710999\n",
            "R²: 0.9824982285499573\n",
            "============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_shelf_life(ripeness, weight, temperature, humidity, storage_days):\n",
        "    df_input = pd.DataFrame([{\n",
        "        \"batch_ripeness_level\": ripeness,\n",
        "        \"batch_avg_weight_g\": weight,\n",
        "        \"temperature_C\": temperature,\n",
        "        \"humidity_%\": humidity,\n",
        "        \"storage_days_before_shipping\": storage_days\n",
        "    }])\n",
        "\n",
        "    X_proc = preprocessor_1.transform(df_input)\n",
        "    X_proc = X_proc.toarray() if hasattr(X_proc, \"toarray\") else X_proc\n",
        "\n",
        "    shelf_life = model1_tf.predict(X_proc).flatten()[0]\n",
        "    return shelf_life\n",
        "\n",
        "# Example:\n",
        "print(\"Example shelf life:\", predict_shelf_life(\"Semi-ripe\", 300, 12, 85, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5cIpRaTqAoY",
        "outputId": "da0ae779-1941-438b-eac6-5b3b9d3cc33f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "Example shelf life: 10.640306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_excel(\"model2_srilanka_1500_rows.xlsx\")\n",
        "\n",
        "print(\"Model 2 head:\")\n",
        "print(df2.head())\n",
        "print(\"Columns:\", df2.columns.tolist())\n",
        "\n",
        "# Drop fully empty rows\n",
        "df2 = df2.dropna(how=\"all\")\n",
        "\n",
        "# Drop rows missing important values\n",
        "df2 = df2.dropna(subset=[\n",
        "    \"number_of_mangoes\",\n",
        "    \"batch_ripeness_level\",\n",
        "    \"batch_avg_weight_g\",\n",
        "    \"destination_country\",\n",
        "    \"transport_mode\",\n",
        "    \"transport_days\",\n",
        "    \"box_type\",\n",
        "    \"padding_type\",\n",
        "    \"expected_damage_%\"\n",
        "])\n",
        "\n",
        "print(\"Rows after cleaning (Model 2):\", len(df2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXMnD5suqKs7",
        "outputId": "2bc2a9d0-2c91-4a86-b8f1-6d8bdb1e2f4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 head:\n",
            "   number_of_mangoes batch_ripeness_level  batch_avg_weight_g  \\\n",
            "0                620            Semi-ripe                 295   \n",
            "1                480                 Ripe                 310   \n",
            "2               1400               Unripe                 270   \n",
            "3                520            Semi-ripe                 300   \n",
            "4                430                 Ripe                 308   \n",
            "\n",
            "   predicted_shelf_life_days destination_country transport_mode  \\\n",
            "0                         10                 UAE            Air   \n",
            "1                          4               Qatar            Air   \n",
            "2                         18        Saudi Arabia            Sea   \n",
            "3                         11            Maldives            Air   \n",
            "4                          5              Kuwait            Air   \n",
            "\n",
            "   transport_days       box_type padding_type box_size_cm  expected_damage_%  \n",
            "0               1     Fiberboard         Foam    40x30x18                  3  \n",
            "1               1     Corrugated         Foam    35x25x15                  6  \n",
            "2              11  Plastic Crate        Paper    50x40x22                  7  \n",
            "3               1     Fiberboard        Paper    38x28x17                  4  \n",
            "4               2     Corrugated         Foam    36x26x16                  7  \n",
            "Columns: ['number_of_mangoes', 'batch_ripeness_level', 'batch_avg_weight_g', 'predicted_shelf_life_days', 'destination_country', 'transport_mode', 'transport_days', 'box_type', 'padding_type', 'box_size_cm', 'expected_damage_%']\n",
            "Rows after cleaning (Model 2): 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols_2 = [\n",
        "    \"number_of_mangoes\",\n",
        "    \"batch_ripeness_level\",\n",
        "    \"batch_avg_weight_g\",\n",
        "    \"destination_country\",\n",
        "    \"transport_mode\",\n",
        "    \"transport_days\"\n",
        "]\n",
        "\n",
        "X2 = df2[feature_cols_2]\n",
        "\n",
        "y_damage = df2[\"expected_damage_%\"].values.astype(\"float32\")\n",
        "y_box_raw = df2[\"box_type\"].values\n",
        "y_padding_raw = df2[\"padding_type\"].values\n",
        "\n",
        "# Label encode box_type and padding_type\n",
        "le_box = LabelEncoder()\n",
        "le_padding = LabelEncoder()\n",
        "\n",
        "y_box = le_box.fit_transform(y_box_raw)\n",
        "y_padding = le_padding.fit_transform(y_padding_raw)\n",
        "\n",
        "print(\"Box classes:\", le_box.classes_)\n",
        "print(\"Padding classes:\", le_padding.classes_)\n",
        "\n",
        "# Split\n",
        "X2_train, X2_test, y_dmg_train, y_dmg_test, y_box_train, y_box_test, y_pad_train, y_pad_test = train_test_split(\n",
        "    X2, y_damage, y_box, y_padding, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Preprocessing (same structure as before)\n",
        "cat_cols_2 = [\"batch_ripeness_level\", \"destination_country\", \"transport_mode\"]\n",
        "num_cols_2 = [\"number_of_mangoes\", \"batch_avg_weight_g\", \"transport_days\"]\n",
        "\n",
        "preprocessor_2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_2),\n",
        "        (\"num\", StandardScaler(), num_cols_2)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Fit and transform\n",
        "X2_train_proc = preprocessor_2.fit_transform(X2_train)\n",
        "X2_test_proc  = preprocessor_2.transform(X2_test)\n",
        "\n",
        "X2_train_proc = X2_train_proc.toarray() if hasattr(X2_train_proc, \"toarray\") else X2_train_proc\n",
        "X2_test_proc  = X2_test_proc.toarray() if hasattr(X2_test_proc, \"toarray\") else X2_test_proc\n",
        "\n",
        "print(\"Processed Model 2 shape:\", X2_train_proc.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdOH96AsqO2W",
        "outputId": "020a0c04-5e57-4d4f-cf2a-6ecb45c3e44c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box classes: ['Corrugated' 'Fiberboard' 'Plastic Crate']\n",
            "Padding classes: ['Foam' 'Paper']\n",
            "Processed Model 2 shape: (1200, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim_2 = X2_train_proc.shape[1]\n",
        "\n",
        "damage_model = models.Sequential([\n",
        "    layers.Input(shape=(input_dim_2,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)   # regression output\n",
        "])\n",
        "\n",
        "damage_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "damage_model.summary()\n",
        "\n",
        "history_dmg = damage_model.fit(\n",
        "    X2_train_proc, y_dmg_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DYFMvkWyqUBs",
        "outputId": "c990fef8-28c5-4823-da86-357285881f78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,457\u001b[0m (13.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,457</span> (13.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,457\u001b[0m (13.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,457</span> (13.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 53.6810 - mae: 6.6199 - val_loss: 36.2431 - val_mae: 5.3780\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.5054 - mae: 4.7458 - val_loss: 9.9242 - val_mae: 2.5673\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4962 - mae: 2.0228 - val_loss: 2.4659 - val_mae: 1.2977\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3539 - mae: 1.2694 - val_loss: 2.1260 - val_mae: 1.2213\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0887 - mae: 1.1952 - val_loss: 2.0354 - val_mae: 1.1972\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0375 - mae: 1.1799 - val_loss: 2.0182 - val_mae: 1.1931\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9826 - mae: 1.1564 - val_loss: 1.9988 - val_mae: 1.1867\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0068 - mae: 1.1780 - val_loss: 1.9862 - val_mae: 1.1848\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0041 - mae: 1.1769 - val_loss: 1.9708 - val_mae: 1.1818\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0610 - mae: 1.1860 - val_loss: 1.9622 - val_mae: 1.1766\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9759 - mae: 1.1675 - val_loss: 1.9612 - val_mae: 1.1773\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8871 - mae: 1.1358 - val_loss: 1.9520 - val_mae: 1.1751\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7423 - mae: 1.0808 - val_loss: 1.9596 - val_mae: 1.1745\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8003 - mae: 1.1037 - val_loss: 1.9566 - val_mae: 1.1763\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0772 - mae: 1.1891 - val_loss: 1.9424 - val_mae: 1.1699\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8489 - mae: 1.1267 - val_loss: 1.9455 - val_mae: 1.1672\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8656 - mae: 1.1258 - val_loss: 1.9966 - val_mae: 1.1869\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0036 - mae: 1.1728 - val_loss: 1.9590 - val_mae: 1.1776\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9395 - mae: 1.1468 - val_loss: 1.9340 - val_mae: 1.1672\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8817 - mae: 1.1327 - val_loss: 1.9445 - val_mae: 1.1693\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8636 - mae: 1.1272 - val_loss: 1.9364 - val_mae: 1.1668\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8752 - mae: 1.1323 - val_loss: 1.9242 - val_mae: 1.1637\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9423 - mae: 1.1569 - val_loss: 1.9492 - val_mae: 1.1674\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8793 - mae: 1.1271 - val_loss: 1.9255 - val_mae: 1.1611\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8431 - mae: 1.1187 - val_loss: 1.9586 - val_mae: 1.1740\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7155 - mae: 1.0778 - val_loss: 1.9401 - val_mae: 1.1645\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7927 - mae: 1.1117 - val_loss: 1.9347 - val_mae: 1.1614\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7998 - mae: 1.0935 - val_loss: 1.9370 - val_mae: 1.1633\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8316 - mae: 1.1090 - val_loss: 1.9334 - val_mae: 1.1647\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8897 - mae: 1.1390 - val_loss: 1.9398 - val_mae: 1.1672\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9617 - mae: 1.1563 - val_loss: 1.9254 - val_mae: 1.1604\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7242 - mae: 1.0795 - val_loss: 1.9306 - val_mae: 1.1653\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8248 - mae: 1.1244 - val_loss: 1.9330 - val_mae: 1.1619\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8203 - mae: 1.1030 - val_loss: 1.9228 - val_mae: 1.1574\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8459 - mae: 1.1086 - val_loss: 1.9168 - val_mae: 1.1573\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6682 - mae: 1.0585 - val_loss: 1.9143 - val_mae: 1.1574\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7314 - mae: 1.0897 - val_loss: 1.9666 - val_mae: 1.1697\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8420 - mae: 1.1003 - val_loss: 1.9339 - val_mae: 1.1628\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7171 - mae: 1.0685 - val_loss: 2.0242 - val_mae: 1.1808\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8312 - mae: 1.1254 - val_loss: 1.9254 - val_mae: 1.1582\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7990 - mae: 1.1172 - val_loss: 1.9205 - val_mae: 1.1588\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8565 - mae: 1.1129 - val_loss: 1.9161 - val_mae: 1.1552\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8749 - mae: 1.1338 - val_loss: 1.9206 - val_mae: 1.1585\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7569 - mae: 1.0820 - val_loss: 1.9105 - val_mae: 1.1527\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7145 - mae: 1.0823 - val_loss: 1.9170 - val_mae: 1.1563\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6826 - mae: 1.0685 - val_loss: 1.9011 - val_mae: 1.1515\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8970 - mae: 1.1372 - val_loss: 1.9382 - val_mae: 1.1604\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8428 - mae: 1.1057 - val_loss: 1.9355 - val_mae: 1.1591\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7548 - mae: 1.0854 - val_loss: 1.9311 - val_mae: 1.1616\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7060 - mae: 1.0716 - val_loss: 1.9933 - val_mae: 1.1723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_dmg_pred = damage_model.predict(X2_test_proc).flatten()\n",
        "\n",
        "mae_d = mean_absolute_error(y_dmg_test, y_dmg_pred)\n",
        "r2_d  = r2_score(y_dmg_test, y_dmg_pred)\n",
        "\n",
        "print(\"===== MODEL 2A – Damage (TensorFlow) =====\")\n",
        "print(\"MAE:\", mae_d)\n",
        "print(\"R²:\", r2_d)\n",
        "print(\"=========================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqTrz3FOqlYA",
        "outputId": "27940263-e7bb-4557-a6b3-ce068b69876e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "===== MODEL 2A – Damage (TensorFlow) =====\n",
            "MAE: 1.1903784275054932\n",
            "R²: 0.794545590877533\n",
            "=========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_box_classes = len(le_box.classes_)\n",
        "\n",
        "box_model = models.Sequential([\n",
        "    layers.Input(shape=(input_dim_2,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(num_box_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "box_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "box_model.summary()\n",
        "\n",
        "history_box = box_model.fit(\n",
        "    X2_train_proc, y_box_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NHwZwDH3qpqN",
        "outputId": "5f53a0ca-522a-4ad4-f33c-fd21d3c2547c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,523\u001b[0m (13.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,523</span> (13.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,523\u001b[0m (13.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,523</span> (13.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4732 - loss: 1.0737 - val_accuracy: 0.7042 - val_loss: 0.8922\n",
            "Epoch 2/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6907 - loss: 0.8527 - val_accuracy: 0.7250 - val_loss: 0.7818\n",
            "Epoch 3/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7192 - loss: 0.7640 - val_accuracy: 0.7292 - val_loss: 0.7403\n",
            "Epoch 4/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7130 - loss: 0.7361 - val_accuracy: 0.7333 - val_loss: 0.7305\n",
            "Epoch 5/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.7440 - val_accuracy: 0.7333 - val_loss: 0.7318\n",
            "Epoch 6/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.7037 - val_accuracy: 0.7333 - val_loss: 0.7333\n",
            "Epoch 7/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.7058 - val_accuracy: 0.7333 - val_loss: 0.7318\n",
            "Epoch 8/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7107 - loss: 0.7332 - val_accuracy: 0.7292 - val_loss: 0.7336\n",
            "Epoch 9/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7169 - loss: 0.7383 - val_accuracy: 0.7333 - val_loss: 0.7341\n",
            "Epoch 10/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7239 - loss: 0.7141 - val_accuracy: 0.7208 - val_loss: 0.7365\n",
            "Epoch 11/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7441 - loss: 0.6865 - val_accuracy: 0.7458 - val_loss: 0.7332\n",
            "Epoch 12/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7300 - loss: 0.7095 - val_accuracy: 0.7417 - val_loss: 0.7365\n",
            "Epoch 13/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7373 - loss: 0.7146 - val_accuracy: 0.7375 - val_loss: 0.7353\n",
            "Epoch 14/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7381 - loss: 0.6870 - val_accuracy: 0.7375 - val_loss: 0.7327\n",
            "Epoch 15/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7284 - loss: 0.6940 - val_accuracy: 0.7375 - val_loss: 0.7388\n",
            "Epoch 16/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7465 - loss: 0.6703 - val_accuracy: 0.7458 - val_loss: 0.7362\n",
            "Epoch 17/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7242 - loss: 0.7132 - val_accuracy: 0.7375 - val_loss: 0.7416\n",
            "Epoch 18/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7202 - loss: 0.7057 - val_accuracy: 0.7375 - val_loss: 0.7414\n",
            "Epoch 19/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.6745 - val_accuracy: 0.7500 - val_loss: 0.7403\n",
            "Epoch 20/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.6939 - val_accuracy: 0.7500 - val_loss: 0.7377\n",
            "Epoch 21/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7514 - loss: 0.6790 - val_accuracy: 0.7375 - val_loss: 0.7394\n",
            "Epoch 22/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.6762 - val_accuracy: 0.7458 - val_loss: 0.7472\n",
            "Epoch 23/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7580 - loss: 0.6620 - val_accuracy: 0.7333 - val_loss: 0.7461\n",
            "Epoch 24/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7183 - loss: 0.7257 - val_accuracy: 0.7500 - val_loss: 0.7451\n",
            "Epoch 25/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7221 - loss: 0.7045 - val_accuracy: 0.7375 - val_loss: 0.7474\n",
            "Epoch 26/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7609 - loss: 0.6617 - val_accuracy: 0.7458 - val_loss: 0.7462\n",
            "Epoch 27/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.6667 - val_accuracy: 0.7458 - val_loss: 0.7447\n",
            "Epoch 28/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7175 - loss: 0.7029 - val_accuracy: 0.7458 - val_loss: 0.7445\n",
            "Epoch 29/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.6975 - val_accuracy: 0.7417 - val_loss: 0.7459\n",
            "Epoch 30/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7207 - loss: 0.6945 - val_accuracy: 0.7500 - val_loss: 0.7424\n",
            "Epoch 31/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7151 - loss: 0.7186 - val_accuracy: 0.7417 - val_loss: 0.7503\n",
            "Epoch 32/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7482 - loss: 0.6412 - val_accuracy: 0.7375 - val_loss: 0.7487\n",
            "Epoch 33/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7268 - loss: 0.6890 - val_accuracy: 0.7458 - val_loss: 0.7491\n",
            "Epoch 34/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.6382 - val_accuracy: 0.7500 - val_loss: 0.7511\n",
            "Epoch 35/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7619 - loss: 0.6517 - val_accuracy: 0.7375 - val_loss: 0.7522\n",
            "Epoch 36/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7580 - loss: 0.6206 - val_accuracy: 0.7292 - val_loss: 0.7529\n",
            "Epoch 37/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.6540 - val_accuracy: 0.7500 - val_loss: 0.7548\n",
            "Epoch 38/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 0.6840 - val_accuracy: 0.7250 - val_loss: 0.7559\n",
            "Epoch 39/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6189 - val_accuracy: 0.7375 - val_loss: 0.7598\n",
            "Epoch 40/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7488 - loss: 0.6581 - val_accuracy: 0.7458 - val_loss: 0.7518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_box_pred_probs = box_model.predict(X2_test_proc)\n",
        "y_box_pred = np.argmax(y_box_pred_probs, axis=1)\n",
        "\n",
        "acc_box = accuracy_score(y_box_test, y_box_pred)\n",
        "print(\"===== MODEL 2B – Box Type (TensorFlow) =====\")\n",
        "print(\"Accuracy:\", acc_box)\n",
        "print(\"============================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDsveYbgqxI6",
        "outputId": "9a5159bc-b11d-42c0-dc4d-4dd02257cec6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "===== MODEL 2B – Box Type (TensorFlow) =====\n",
            "Accuracy: 0.74\n",
            "============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_pad_classes = len(le_padding.classes_)\n",
        "\n",
        "padding_model = models.Sequential([\n",
        "    layers.Input(shape=(input_dim_2,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(num_pad_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "padding_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "padding_model.summary()\n",
        "\n",
        "history_pad = padding_model.fit(\n",
        "    X2_train_proc, y_pad_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E_ws-0wPq2lT",
        "outputId": "e17ad418-b3ba-494a-95b8-50adb4541795"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,490\u001b[0m (13.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,490</span> (13.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,490\u001b[0m (13.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,490</span> (13.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6654 - loss: 0.5956 - val_accuracy: 0.7875 - val_loss: 0.4926\n",
            "Epoch 2/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.4928 - val_accuracy: 0.8000 - val_loss: 0.4857\n",
            "Epoch 3/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4752 - val_accuracy: 0.8083 - val_loss: 0.4842\n",
            "Epoch 4/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4783 - val_accuracy: 0.7958 - val_loss: 0.4747\n",
            "Epoch 5/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4780 - val_accuracy: 0.8000 - val_loss: 0.4818\n",
            "Epoch 6/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.4954 - val_accuracy: 0.8000 - val_loss: 0.4739\n",
            "Epoch 7/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.4876 - val_accuracy: 0.7917 - val_loss: 0.4848\n",
            "Epoch 8/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7621 - loss: 0.4822 - val_accuracy: 0.7958 - val_loss: 0.4754\n",
            "Epoch 9/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7873 - loss: 0.4674 - val_accuracy: 0.7875 - val_loss: 0.4783\n",
            "Epoch 10/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7674 - loss: 0.4662 - val_accuracy: 0.8000 - val_loss: 0.4801\n",
            "Epoch 11/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7803 - loss: 0.4551 - val_accuracy: 0.7958 - val_loss: 0.4872\n",
            "Epoch 12/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8100 - loss: 0.4478 - val_accuracy: 0.7833 - val_loss: 0.4740\n",
            "Epoch 13/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.4760 - val_accuracy: 0.7917 - val_loss: 0.4849\n",
            "Epoch 14/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7741 - loss: 0.4691 - val_accuracy: 0.7917 - val_loss: 0.4888\n",
            "Epoch 15/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7696 - loss: 0.4811 - val_accuracy: 0.7875 - val_loss: 0.4766\n",
            "Epoch 16/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8003 - loss: 0.4463 - val_accuracy: 0.7875 - val_loss: 0.4953\n",
            "Epoch 17/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8007 - loss: 0.4571 - val_accuracy: 0.7958 - val_loss: 0.4876\n",
            "Epoch 18/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7608 - loss: 0.4899 - val_accuracy: 0.7792 - val_loss: 0.4846\n",
            "Epoch 19/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4373 - val_accuracy: 0.7958 - val_loss: 0.4856\n",
            "Epoch 20/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.4864 - val_accuracy: 0.7833 - val_loss: 0.4837\n",
            "Epoch 21/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7750 - loss: 0.4629 - val_accuracy: 0.7792 - val_loss: 0.4785\n",
            "Epoch 22/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7793 - loss: 0.4473 - val_accuracy: 0.7917 - val_loss: 0.4878\n",
            "Epoch 23/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4626 - val_accuracy: 0.7875 - val_loss: 0.4795\n",
            "Epoch 24/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4541 - val_accuracy: 0.7792 - val_loss: 0.4994\n",
            "Epoch 25/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4663 - val_accuracy: 0.7917 - val_loss: 0.4804\n",
            "Epoch 26/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.4460 - val_accuracy: 0.7958 - val_loss: 0.4826\n",
            "Epoch 27/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7928 - loss: 0.4486 - val_accuracy: 0.7792 - val_loss: 0.4836\n",
            "Epoch 28/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4641 - val_accuracy: 0.7875 - val_loss: 0.4964\n",
            "Epoch 29/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.4526 - val_accuracy: 0.7958 - val_loss: 0.4861\n",
            "Epoch 30/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.4339 - val_accuracy: 0.7833 - val_loss: 0.4980\n",
            "Epoch 31/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.4401 - val_accuracy: 0.7917 - val_loss: 0.4944\n",
            "Epoch 32/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.4689 - val_accuracy: 0.7792 - val_loss: 0.4995\n",
            "Epoch 33/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.4296 - val_accuracy: 0.7875 - val_loss: 0.4874\n",
            "Epoch 34/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4497 - val_accuracy: 0.7917 - val_loss: 0.4869\n",
            "Epoch 35/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7816 - loss: 0.4578 - val_accuracy: 0.7833 - val_loss: 0.4884\n",
            "Epoch 36/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.4312 - val_accuracy: 0.7917 - val_loss: 0.4889\n",
            "Epoch 37/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7700 - loss: 0.4733 - val_accuracy: 0.8000 - val_loss: 0.4906\n",
            "Epoch 38/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4213 - val_accuracy: 0.7875 - val_loss: 0.4899\n",
            "Epoch 39/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.4273 - val_accuracy: 0.7833 - val_loss: 0.4961\n",
            "Epoch 40/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4544 - val_accuracy: 0.7833 - val_loss: 0.4831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pad_pred_probs = padding_model.predict(X2_test_proc)\n",
        "y_pad_pred = np.argmax(y_pad_pred_probs, axis=1)\n",
        "\n",
        "acc_pad = accuracy_score(y_pad_test, y_pad_pred)\n",
        "print(\"===== MODEL 2C – Padding Type (TensorFlow) =====\")\n",
        "print(\"Accuracy:\", acc_pad)\n",
        "print(\"===============================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WlZK-dUq9Zu",
        "outputId": "e2c46d0a-a3c1-4310-db8d-18f6e0f0a744"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "===== MODEL 2C – Padding Type (TensorFlow) =====\n",
            "Accuracy: 0.7933333333333333\n",
            "===============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_full_packaging_tf(\n",
        "    ripeness, weight, temperature, humidity, storage_days,\n",
        "    number_of_mangoes, destination_country, transport_mode, transport_days\n",
        "):\n",
        "    # 1) Predict shelf life using Model 1\n",
        "    shelf_life = predict_shelf_life(ripeness, weight, temperature, humidity, storage_days)\n",
        "\n",
        "    # 2) Prepare input for Model 2\n",
        "    df_input2 = pd.DataFrame([{\n",
        "        \"number_of_mangoes\": number_of_mangoes,\n",
        "        \"batch_ripeness_level\": ripeness,\n",
        "        \"batch_avg_weight_g\": weight,\n",
        "        \"destination_country\": destination_country,\n",
        "        \"transport_mode\": transport_mode,\n",
        "        \"transport_days\": transport_days\n",
        "    }])\n",
        "\n",
        "    X2_proc = preprocessor_2.transform(df_input2)\n",
        "    X2_proc = X2_proc.toarray() if hasattr(X2_proc, \"toarray\") else X2_proc\n",
        "\n",
        "    # 3) Predict damage\n",
        "    damage = float(damage_model.predict(X2_proc).flatten()[0])\n",
        "\n",
        "    # 4) Predict box & padding\n",
        "    box_probs = box_model.predict(X2_proc)\n",
        "    pad_probs = padding_model.predict(X2_proc)\n",
        "\n",
        "    box_idx = int(np.argmax(box_probs, axis=1)[0])\n",
        "    pad_idx = int(np.argmax(pad_probs, axis=1)[0])\n",
        "\n",
        "    box_label = le_box.inverse_transform([box_idx])[0]\n",
        "    pad_label = le_padding.inverse_transform([pad_idx])[0]\n",
        "\n",
        "    # 5) Risk check based on shelf life vs transport\n",
        "    if shelf_life < transport_days:\n",
        "        risk = \"⚠ HIGH RISK: Shelf life is lower than transport duration.\"\n",
        "    else:\n",
        "        risk = \"✓ Safe: Shelf life is acceptable for transport.\"\n",
        "\n",
        "    return {\n",
        "        \"Shelf Life (days)\": round(float(shelf_life), 2),\n",
        "        \"Transport Days\": transport_days,\n",
        "        \"Risk\": risk,\n",
        "        \"Predicted Damage (%)\": round(damage, 2),\n",
        "        \"Recommended Box Type\": box_label,\n",
        "        \"Recommended Padding Type\": pad_label\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "result = predict_full_packaging_tf(\n",
        "    ripeness=\"Semi-ripe\",\n",
        "    weight=300,\n",
        "    temperature=12,\n",
        "    humidity=85,\n",
        "    storage_days=1,\n",
        "    number_of_mangoes=1000,\n",
        "    destination_country=\"Germany\",\n",
        "    transport_mode=\"Sea\",\n",
        "    transport_days=20\n",
        ")\n",
        "result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX8M75x3rCyc",
        "outputId": "5e5530de-bdc9-4ec9-9f6d-24444fd7839c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Shelf Life (days)': 10.64,\n",
              " 'Transport Days': 20,\n",
              " 'Risk': '⚠ HIGH RISK: Shelf life is lower than transport duration.',\n",
              " 'Predicted Damage (%)': 8.65,\n",
              " 'Recommended Box Type': 'Fiberboard',\n",
              " 'Recommended Padding Type': 'Paper'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ECO RULES ---\n",
        "eco_rules = {\n",
        "    \"Fiberboard\": \"Eco-Friendly\",\n",
        "    \"Corrugated\": \"Eco-Friendly\",\n",
        "    \"Plastic Crate\": \"Not Eco-Friendly\",\n",
        "    \"Paper Pulp\": \"Eco-Friendly\",\n",
        "    \"Recycled Cardboard\": \"Eco-Friendly\"\n",
        "}\n",
        "\n",
        "# --- LEGAL RULES FOR EACH COUNTRY ---\n",
        "legal_rules = {\n",
        "    \"Germany\": {\"allowed\": [\"Fiberboard\", \"Corrugated\"], \"banned\": [\"Plastic Crate\"]},\n",
        "    \"France\": {\"allowed\": [\"Fiberboard\", \"Corrugated\"], \"banned\": [\"Plastic Crate\"]},\n",
        "    \"UK\":     {\"allowed\": [\"Fiberboard\", \"Corrugated\"], \"banned\": [\"Plastic Crate\"]},\n",
        "\n",
        "    \"Japan\":  {\"allowed\": [\"Fiberboard\"], \"banned\": [\"Plastic Crate\", \"Corrugated\"]},\n",
        "\n",
        "    \"UAE\":    {\"allowed\": [\"Fiberboard\", \"Plastic Crate\"], \"banned\": []},\n",
        "    \"Saudi Arabia\": {\"allowed\": [\"Fiberboard\", \"Plastic Crate\"], \"banned\": []},\n",
        "    \"Qatar\":  {\"allowed\": [\"Fiberboard\", \"Plastic Crate\"], \"banned\": []}\n",
        "}\n"
      ],
      "metadata": {
        "id": "msqh2IIdrKPb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_packaging_recommendation_tf(\n",
        "    ripeness, weight, temperature, humidity, storage_days,\n",
        "    number_of_mangoes, destination_country, transport_mode, transport_days\n",
        "):\n",
        "\n",
        "    # --- STEP 1: Shelf-life prediction ---\n",
        "    shelf_life = predict_shelf_life(ripeness, weight, temperature, humidity, storage_days)\n",
        "\n",
        "    # --- STEP 2: Prepare input for Model 2 ---\n",
        "    df_input2 = pd.DataFrame([{\n",
        "        \"number_of_mangoes\": number_of_mangoes,\n",
        "        \"batch_ripeness_level\": ripeness,\n",
        "        \"batch_avg_weight_g\": weight,\n",
        "        \"destination_country\": destination_country,\n",
        "        \"transport_mode\": transport_mode,\n",
        "        \"transport_days\": transport_days\n",
        "    }])\n",
        "\n",
        "    X2_proc = preprocessor_2.transform(df_input2)\n",
        "    X2_proc = X2_proc.toarray() if hasattr(X2_proc, \"toarray\") else X2_proc\n",
        "\n",
        "    # --- STEP 3: Predict damage ---\n",
        "    damage = float(damage_model.predict(X2_proc).flatten()[0])\n",
        "\n",
        "    # --- STEP 4: Predict box & padding ---\n",
        "    box_probs = box_model.predict(X2_proc)\n",
        "    pad_probs = padding_model.predict(X2_proc)\n",
        "\n",
        "    box_idx = int(np.argmax(box_probs))\n",
        "    pad_idx = int(np.argmax(pad_probs))\n",
        "\n",
        "    box_label = le_box.inverse_transform([box_idx])[0]\n",
        "    padding_label = le_padding.inverse_transform([pad_idx])[0]\n",
        "\n",
        "    # --- STEP 5: LEGAL CHECK ---\n",
        "    rules = legal_rules.get(destination_country, None)\n",
        "    legal_status = \"Unknown\"\n",
        "    legal_note = \"\"\n",
        "\n",
        "    if rules:\n",
        "        if box_label in rules[\"banned\"]:\n",
        "            old = box_label\n",
        "            box_label = rules[\"allowed\"][0]  # auto-correct\n",
        "            legal_status = \"Illegal (Corrected)\"\n",
        "            legal_note = f\"'{old}' is banned in {destination_country}. Changed to '{box_label}'.\"\n",
        "        else:\n",
        "            legal_status = \"Legal\"\n",
        "    else:\n",
        "        legal_status = \"Unknown\"\n",
        "        legal_note = \"No rule data found for this country.\"\n",
        "\n",
        "    # --- STEP 6: ECO CHECK ---\n",
        "    eco_status = eco_rules.get(box_label, \"Unknown\")\n",
        "\n",
        "    # --- STEP 7: RISK CHECK ---\n",
        "    if shelf_life < transport_days:\n",
        "        risk = \"⚠ HIGH RISK — Shelf life is lower than transport duration!\"\n",
        "    else:\n",
        "        risk = \"✓ SAFE — Shelf life is acceptable for transport.\"\n",
        "\n",
        "    # --- STEP 8: FINAL RECOMMENDATION TEXT ---\n",
        "    final_text = (\n",
        "        f\"{risk}\\n\\n\"\n",
        "        f\"📦 Recommended Box Type: {box_label}\\n\"\n",
        "        f\"🧽 Recommended Padding: {padding_label}\\n\"\n",
        "        f\"🌱 Eco Status: {eco_status}\\n\"\n",
        "        f\"⚖ Legal Status: {legal_status} — {legal_note}\\n\\n\"\n",
        "        f\"💡 Expected Damage: {round(damage, 2)}%\\n\"\n",
        "        f\"🕒 Shelf Life: {round(shelf_life, 2)} days\\n\"\n",
        "        f\"🚢 Transport Duration: {transport_days} days\\n\\n\"\n",
        "        f\"➡ Use {box_label} with {padding_label}. \"\n",
        "        f\"This achieves the safest shipment under current conditions.\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"Shelf Life (days)\": round(float(shelf_life), 2),\n",
        "        \"Transport Days\": transport_days,\n",
        "        \"Risk\": risk,\n",
        "        \"Predicted Damage (%)\": round(damage, 2),\n",
        "        \"Recommended Box Type\": box_label,\n",
        "        \"Recommended Padding Type\": padding_label,\n",
        "        \"Eco Status\": eco_status,\n",
        "        \"Legal Status\": legal_status,\n",
        "        \"Legal Note\": legal_note,\n",
        "        \"Final Recommendation\": final_text\n",
        "    }\n"
      ],
      "metadata": {
        "id": "izR8Ux3GrN5X"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = final_packaging_recommendation_tf(\n",
        "    ripeness=\"Semi-ripe\",\n",
        "    weight=300,\n",
        "    temperature=12,\n",
        "    humidity=85,\n",
        "    storage_days=1,\n",
        "    number_of_mangoes=1000,\n",
        "    destination_country=\"Germany\",\n",
        "    transport_mode=\"Sea\",\n",
        "    transport_days=20\n",
        ")\n",
        "\n",
        "result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkUBAt2TrS5L",
        "outputId": "4bb5aff2-e2be-45c1-908d-4379baa22912"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Shelf Life (days)': 10.64,\n",
              " 'Transport Days': 20,\n",
              " 'Risk': '⚠ HIGH RISK — Shelf life is lower than transport duration!',\n",
              " 'Predicted Damage (%)': 8.65,\n",
              " 'Recommended Box Type': 'Fiberboard',\n",
              " 'Recommended Padding Type': 'Paper',\n",
              " 'Eco Status': 'Eco-Friendly',\n",
              " 'Legal Status': 'Legal',\n",
              " 'Legal Note': '',\n",
              " 'Final Recommendation': '⚠ HIGH RISK — Shelf life is lower than transport duration!\\n\\n📦 Recommended Box Type: Fiberboard\\n🧽 Recommended Padding: Paper\\n🌱 Eco Status: Eco-Friendly\\n⚖ Legal Status: Legal — \\n\\n💡 Expected Damage: 8.65%\\n🕒 Shelf Life: 10.640000343322754 days\\n🚢 Transport Duration: 20 days\\n\\n➡ Use Fiberboard with Paper. This achieves the safest shipment under current conditions.'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}